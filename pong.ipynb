{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pong.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_jQ1tEQCxwRx"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kruegz/pong/blob/main/pong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p62G8M_viUJp"
      },
      "source": [
        "# Playing Pong with Reinforcement Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://gym.openai.com/envs/Pong-v0/\n",
        "https://towardsdatascience.com/deep-q-network-dqn-i-bce08bdf2af\n",
        "https://towardsdatascience.com/getting-an-ai-to-play-atari-pong-with-deep-reinforcement-learning-47b0c56e78ae\n"
      ],
      "metadata": {
        "id": "QbCoedrbk1Oj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glLwIctHiUJq"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Import necessary packages and configure global settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y67fEqlclDEH",
        "outputId": "c08787de-52df-44be-989b-3bed09d0d499"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBeQhPi2S4m5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae50130-cc94-4df2-afc3-63e604940ce8"
      },
      "source": [
        "%%bash\n",
        "\n",
        "# Install main packages\n",
        "pip install gym > /dev/null 2>&1\n",
        "pip install pyglet > /dev/null 2>&1\n",
        "pip install atari-py > /dev/null 2>&1\n",
        "\n",
        "# Install additional packages for visualization\n",
        "sudo apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "pip install pyvirtualdisplay > /dev/null 2>&1\n",
        "pip install git+https://github.com/tensorflow/docs > /dev/null 2>&1\n",
        "\n",
        "sudo apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "pip install -U colabgymrender > /dev/null 2>&1\n",
        "\n",
        "\n",
        "# Download and install Atari ROMs\n",
        "# https://github.com/openai/atari-py#roms\n",
        "# http://www.atarimania.com/rom_collection_archive_atari_2600_roms.html\n",
        "wget http://www.atarimania.com/roms/Roms.rar\n",
        "unrar e Roms.rar\n",
        "python -m atari_py.import_roms .\n",
        "\n",
        "export DISPLAY=localhost:0.0 "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from Roms.rar\n",
            "\n",
            "No files to extract\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2022-02-02 21:04:24--  http://www.atarimania.com/roms/Roms.rar\n",
            "Resolving www.atarimania.com (www.atarimania.com)... 195.154.81.199\n",
            "Connecting to www.atarimania.com (www.atarimania.com)|195.154.81.199|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11128004 (11M) [application/x-rar-compressed]\n",
            "Saving to: ‘Roms.rar.1’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0%  209K 52s\n",
            "    50K .......... .......... .......... .......... ..........  0%  624K 34s\n",
            "   100K .......... .......... .......... .......... ..........  1%  312K 34s\n",
            "   150K .......... .......... .......... .......... ..........  1%  620K 30s\n",
            "   200K .......... .......... .......... .......... ..........  2%  125M 24s\n",
            "   250K .......... .......... .......... .......... ..........  2%  621K 23s\n",
            "   300K .......... .......... .......... .......... ..........  3%  621K 22s\n",
            "   350K .......... .......... .......... .......... ..........  3%  623K 21s\n",
            "   400K .......... .......... .......... .......... ..........  4%  622K 20s\n",
            "   450K .......... .......... .......... .......... ..........  4%  129M 18s\n",
            "   500K .......... .......... .......... .......... ..........  5%  624K 18s\n",
            "   550K .......... .......... .......... .......... ..........  5%  622K 18s\n",
            "   600K .......... .......... .......... .......... ..........  5%  622K 18s\n",
            "   650K .......... .......... .......... .......... ..........  6%  286M 16s\n",
            "   700K .......... .......... .......... .......... ..........  6%  623K 16s\n",
            "   750K .......... .......... .......... .......... ..........  7%  623K 16s\n",
            "   800K .......... .......... .......... .......... ..........  7%  623K 16s\n",
            "   850K .......... .......... .......... .......... ..........  8%  624K 16s\n",
            "   900K .......... .......... .......... .......... ..........  8%  142M 15s\n",
            "   950K .......... .......... .......... .......... ..........  9%  623K 15s\n",
            "  1000K .......... .......... .......... .......... ..........  9%  622K 15s\n",
            "  1050K .......... .......... .......... .......... .......... 10%  623K 15s\n",
            "  1100K .......... .......... .......... .......... .......... 10%  200M 14s\n",
            "  1150K .......... .......... .......... .......... .......... 11%  624K 14s\n",
            "  1200K .......... .......... .......... .......... .......... 11%  623K 14s\n",
            "  1250K .......... .......... .......... .......... .......... 11%  623K 14s\n",
            "  1300K .......... .......... .......... .......... .......... 12%  624K 14s\n",
            "  1350K .......... .......... .......... .......... .......... 12%  185M 14s\n",
            "  1400K .......... .......... .......... .......... .......... 13%  624K 14s\n",
            "  1450K .......... .......... .......... .......... .......... 13%  622K 14s\n",
            "  1500K .......... .......... .......... .......... .......... 14%  621K 14s\n",
            "  1550K .......... .......... .......... .......... .......... 14%  240M 13s\n",
            "  1600K .......... .......... .......... .......... .......... 15%  624K 13s\n",
            "  1650K .......... .......... .......... .......... .......... 15%  624K 13s\n",
            "  1700K .......... .......... .......... .......... .......... 16%  621K 13s\n",
            "  1750K .......... .......... .......... .......... .......... 16%  623K 13s\n",
            "  1800K .......... .......... .......... .......... .......... 17%  168M 13s\n",
            "  1850K .......... .......... .......... .......... .......... 17%  624K 13s\n",
            "  1900K .......... .......... .......... .......... .......... 17%  624K 12s\n",
            "  1950K .......... .......... .......... .......... .......... 18%  620K 12s\n",
            "  2000K .......... .......... .......... .......... .......... 18%  621K 12s\n",
            "  2050K .......... .......... .......... .......... .......... 19% 89.6M 12s\n",
            "  2100K .......... .......... .......... .......... .......... 19%  625K 12s\n",
            "  2150K .......... .......... .......... .......... .......... 20%  623K 12s\n",
            "  2200K .......... .......... .......... .......... .......... 20%  623K 12s\n",
            "  2250K .......... .......... .......... .......... .......... 21%  253M 12s\n",
            "  2300K .......... .......... .......... .......... .......... 21%  623K 12s\n",
            "  2350K .......... .......... .......... .......... .......... 22%  623K 12s\n",
            "  2400K .......... .......... .......... .......... .......... 22%  624K 12s\n",
            "  2450K .......... .......... .......... .......... .......... 23%  623K 12s\n",
            "  2500K .......... .......... .......... .......... .......... 23%  159M 11s\n",
            "  2550K .......... .......... .......... .......... .......... 23%  623K 11s\n",
            "  2600K .......... .......... .......... .......... .......... 24%  623K 11s\n",
            "  2650K .......... .......... .......... .......... .......... 24%  621K 11s\n",
            "  2700K .......... .......... .......... .......... .......... 25%  269M 11s\n",
            "  2750K .......... .......... .......... .......... .......... 25%  623K 11s\n",
            "  2800K .......... .......... .......... .......... .......... 26%  624K 11s\n",
            "  2850K .......... .......... .......... .......... .......... 26%  622K 11s\n",
            "  2900K .......... .......... .......... .......... .......... 27%  624K 11s\n",
            "  2950K .......... .......... .......... .......... .......... 27%  135M 11s\n",
            "  3000K .......... .......... .......... .......... .......... 28%  623K 11s\n",
            "  3050K .......... .......... .......... .......... .......... 28%  621K 10s\n",
            "  3100K .......... .......... .......... .......... .......... 28%  623K 10s\n",
            "  3150K .......... .......... .......... .......... .......... 29%  204M 10s\n",
            "  3200K .......... .......... .......... .......... .......... 29%  620K 10s\n",
            "  3250K .......... .......... .......... .......... .......... 30%  625K 10s\n",
            "  3300K .......... .......... .......... .......... .......... 30%  623K 10s\n",
            "  3350K .......... .......... .......... .......... .......... 31%  623K 10s\n",
            "  3400K .......... .......... .......... .......... .......... 31%  162M 10s\n",
            "  3450K .......... .......... .......... .......... .......... 32%  623K 10s\n",
            "  3500K .......... .......... .......... .......... .......... 32%  620K 10s\n",
            "  3550K .......... .......... .......... .......... .......... 33%  620K 10s\n",
            "  3600K .......... .......... .......... .......... .......... 33%  624K 10s\n",
            "  3650K .......... .......... .......... .......... .......... 34%  191M 9s\n",
            "  3700K .......... .......... .......... .......... .......... 34%  623K 9s\n",
            "  3750K .......... .......... .......... .......... .......... 34%  621K 9s\n",
            "  3800K .......... .......... .......... .......... .......... 35%  623K 9s\n",
            "  3850K .......... .......... .......... .......... .......... 35%  171M 9s\n",
            "  3900K .......... .......... .......... .......... .......... 36%  624K 9s\n",
            "  3950K .......... .......... .......... .......... .......... 36%  621K 9s\n",
            "  4000K .......... .......... .......... .......... .......... 37%  624K 9s\n",
            "  4050K .......... .......... .......... .......... .......... 37%  619K 9s\n",
            "  4100K .......... .......... .......... .......... .......... 38%  157M 9s\n",
            "  4150K .......... .......... .......... .......... .......... 38%  622K 9s\n",
            "  4200K .......... .......... .......... .......... .......... 39%  623K 9s\n",
            "  4250K .......... .......... .......... .......... .......... 39%  622K 9s\n",
            "  4300K .......... .......... .......... .......... .......... 40%  280M 9s\n",
            "  4350K .......... .......... .......... .......... .......... 40%  623K 9s\n",
            "  4400K .......... .......... .......... .......... .......... 40%  620K 8s\n",
            "  4450K .......... .......... .......... .......... .......... 41%  623K 8s\n",
            "  4500K .......... .......... .......... .......... .......... 41%  624K 8s\n",
            "  4550K .......... .......... .......... .......... .......... 42%  162M 8s\n",
            "  4600K .......... .......... .......... .......... .......... 42%  623K 8s\n",
            "  4650K .......... .......... .......... .......... .......... 43%  624K 8s\n",
            "  4700K .......... .......... .......... .......... .......... 43%  623K 8s\n",
            "  4750K .......... .......... .......... .......... .......... 44%  193M 8s\n",
            "  4800K .......... .......... .......... .......... .......... 44%  621K 8s\n",
            "  4850K .......... .......... .......... .......... .......... 45%  624K 8s\n",
            "  4900K .......... .......... .......... .......... .......... 45%  622K 8s\n",
            "  4950K .......... .......... .......... .......... .......... 46%  623K 8s\n",
            "  5000K .......... .......... .......... .......... .......... 46%  136M 8s\n",
            "  5050K .......... .......... .......... .......... .......... 46%  623K 8s\n",
            "  5100K .......... .......... .......... .......... .......... 47%  620K 7s\n",
            "  5150K .......... .......... .......... .......... .......... 47%  623K 7s\n",
            "  5200K .......... .......... .......... .......... .......... 48%  621K 7s\n",
            "  5250K .......... .......... .......... .......... .......... 48%  122M 7s\n",
            "  5300K .......... .......... .......... .......... .......... 49%  624K 7s\n",
            "  5350K .......... .......... .......... .......... .......... 49%  619K 7s\n",
            "  5400K .......... .......... .......... .......... .......... 50%  621K 7s\n",
            "  5450K .......... .......... .......... .......... .......... 50%  255M 7s\n",
            "  5500K .......... .......... .......... .......... .......... 51%  624K 7s\n",
            "  5550K .......... .......... .......... .......... .......... 51%  621K 7s\n",
            "  5600K .......... .......... .......... .......... .......... 51%  622K 7s\n",
            "  5650K .......... .......... .......... .......... .......... 52%  624K 7s\n",
            "  5700K .......... .......... .......... .......... .......... 52%  177M 7s\n",
            "  5750K .......... .......... .......... .......... .......... 53%  621K 7s\n",
            "  5800K .......... .......... .......... .......... .......... 53%  624K 7s\n",
            "  5850K .......... .......... .......... .......... .......... 54%  622K 6s\n",
            "  5900K .......... .......... .......... .......... .......... 54%  184M 6s\n",
            "  5950K .......... .......... .......... .......... .......... 55%  624K 6s\n",
            "  6000K .......... .......... .......... .......... .......... 55%  620K 6s\n",
            "  6050K .......... .......... .......... .......... .......... 56%  622K 6s\n",
            "  6100K .......... .......... .......... .......... .......... 56%  622K 6s\n",
            "  6150K .......... .......... .......... .......... .......... 57%  213M 6s\n",
            "  6200K .......... .......... .......... .......... .......... 57%  623K 6s\n",
            "  6250K .......... .......... .......... .......... .......... 57%  620K 6s\n",
            "  6300K .......... .......... .......... .......... .......... 58%  619K 6s\n",
            "  6350K .......... .......... .......... .......... .......... 58%  197M 6s\n",
            "  6400K .......... .......... .......... .......... .......... 59%  624K 6s\n",
            "  6450K .......... .......... .......... .......... .......... 59%  622K 6s\n",
            "  6500K .......... .......... .......... .......... .......... 60%  623K 6s\n",
            "  6550K .......... .......... .......... .......... .......... 60%  623K 6s\n",
            "  6600K .......... .......... .......... .......... .......... 61%  128M 5s\n",
            "  6650K .......... .......... .......... .......... .......... 61%  622K 5s\n",
            "  6700K .......... .......... .......... .......... .......... 62%  624K 5s\n",
            "  6750K .......... .......... .......... .......... .......... 62%  621K 5s\n",
            "  6800K .......... .......... .......... .......... .......... 63%  623K 5s\n",
            "  6850K .......... .......... .......... .......... .......... 63%  147M 5s\n",
            "  6900K .......... .......... .......... .......... .......... 63%  622K 5s\n",
            "  6950K .......... .......... .......... .......... .......... 64%  622K 5s\n",
            "  7000K .......... .......... .......... .......... .......... 64%  624K 5s\n",
            "  7050K .......... .......... .......... .......... .......... 65%  155M 5s\n",
            "  7100K .......... .......... .......... .......... .......... 65%  623K 5s\n",
            "  7150K .......... .......... .......... .......... .......... 66%  621K 5s\n",
            "  7200K .......... .......... .......... .......... .......... 66%  620K 5s\n",
            "  7250K .......... .......... .......... .......... .......... 67%  623K 5s\n",
            "  7300K .......... .......... .......... .......... .......... 67%  148M 5s\n",
            "  7350K .......... .......... .......... .......... .......... 68%  620K 4s\n",
            "  7400K .......... .......... .......... .......... .......... 68%  622K 4s\n",
            "  7450K .......... .......... .......... .......... .......... 69%  623K 4s\n",
            "  7500K .......... .......... .......... .......... .......... 69%  163M 4s\n",
            "  7550K .......... .......... .......... .......... .......... 69%  622K 4s\n",
            "  7600K .......... .......... .......... .......... .......... 70%  624K 4s\n",
            "  7650K .......... .......... .......... .......... .......... 70%  623K 4s\n",
            "  7700K .......... .......... .......... .......... .......... 71%  622K 4s\n",
            "  7750K .......... .......... .......... .......... .......... 71%  161M 4s\n",
            "  7800K .......... .......... .......... .......... .......... 72%  624K 4s\n",
            "  7850K .......... .......... .......... .......... .......... 72%  621K 4s\n",
            "  7900K .......... .......... .......... .......... .......... 73%  623K 4s\n",
            "  7950K .......... .......... .......... .......... .......... 73%  188M 4s\n",
            "  8000K .......... .......... .......... .......... .......... 74%  623K 4s\n",
            "  8050K .......... .......... .......... .......... .......... 74%  624K 4s\n",
            "  8100K .......... .......... .......... .......... .......... 74%  621K 4s\n",
            "  8150K .......... .......... .......... .......... .......... 75%  619K 3s\n",
            "  8200K .......... .......... .......... .......... .......... 75%  125M 3s\n",
            "  8250K .......... .......... .......... .......... .......... 76%  624K 3s\n",
            "  8300K .......... .......... .......... .......... .......... 76%  624K 3s\n",
            "  8350K .......... .......... .......... .......... .......... 77%  621K 3s\n",
            "  8400K .......... .......... .......... .......... .......... 77%  623K 3s\n",
            "  8450K .......... .......... .......... .......... .......... 78%  133M 3s\n",
            "  8500K .......... .......... .......... .......... .......... 78%  623K 3s\n",
            "  8550K .......... .......... .......... .......... .......... 79%  620K 3s\n",
            "  8600K .......... .......... .......... .......... .......... 79%  623K 3s\n",
            "  8650K .......... .......... .......... .......... .......... 80%  122M 3s\n",
            "  8700K .......... .......... .......... .......... .......... 80%  622K 3s\n",
            "  8750K .......... .......... .......... .......... .......... 80%  623K 3s\n",
            "  8800K .......... .......... .......... .......... .......... 81%  621K 3s\n",
            "  8850K .......... .......... .......... .......... .......... 81%  624K 3s\n",
            "  8900K .......... .......... .......... .......... .......... 82%  113M 2s\n",
            "  8950K .......... .......... .......... .......... .......... 82%  624K 2s\n",
            "  9000K .......... .......... .......... .......... .......... 83%  623K 2s\n",
            "  9050K .......... .......... .......... .......... .......... 83%  623K 2s\n",
            "  9100K .......... .......... .......... .......... .......... 84%  149M 2s\n",
            "  9150K .......... .......... .......... .......... .......... 84%  622K 2s\n",
            "  9200K .......... .......... .......... .......... .......... 85%  622K 2s\n",
            "  9250K .......... .......... .......... .......... .......... 85%  620K 2s\n",
            "  9300K .......... .......... .......... .......... .......... 86%  623K 2s\n",
            "  9350K .......... .......... .......... .......... .......... 86%  158M 2s\n",
            "  9400K .......... .......... .......... .......... .......... 86%  624K 2s\n",
            "  9450K .......... .......... .......... .......... .......... 87%  623K 2s\n",
            "  9500K .......... .......... .......... .......... .......... 87%  622K 2s\n",
            "  9550K .......... .......... .......... .......... .......... 88%  195M 2s\n",
            "  9600K .......... .......... .......... .......... .......... 88%  623K 2s\n",
            "  9650K .......... .......... .......... .......... .......... 89%  624K 1s\n",
            "  9700K .......... .......... .......... .......... .......... 89%  623K 1s\n",
            "  9750K .......... .......... .......... .......... .......... 90%  621K 1s\n",
            "  9800K .......... .......... .......... .......... .......... 90%  142M 1s\n",
            "  9850K .......... .......... .......... .......... .......... 91%  622K 1s\n",
            "  9900K .......... .......... .......... .......... .......... 91%  620K 1s\n",
            "  9950K .......... .......... .......... .......... .......... 92%  623K 1s\n",
            " 10000K .......... .......... .......... .......... .......... 92%  626K 1s\n",
            " 10050K .......... .......... .......... .......... .......... 92%  125M 1s\n",
            " 10100K .......... .......... .......... .......... .......... 93%  621K 1s\n",
            " 10150K .......... .......... .......... .......... .......... 93%  621K 1s\n",
            " 10200K .......... .......... .......... .......... .......... 94%  619K 1s\n",
            " 10250K .......... .......... .......... .......... .......... 94%  198M 1s\n",
            " 10300K .......... .......... .......... .......... .......... 95%  624K 1s\n",
            " 10350K .......... .......... .......... .......... .......... 95%  623K 1s\n",
            " 10400K .......... .......... .......... .......... .......... 96%  623K 1s\n",
            " 10450K .......... .......... .......... .......... .......... 96%  622K 0s\n",
            " 10500K .......... .......... .......... .......... .......... 97%  130M 0s\n",
            " 10550K .......... .......... .......... .......... .......... 97%  621K 0s\n",
            " 10600K .......... .......... .......... .......... .......... 98%  623K 0s\n",
            " 10650K .......... .......... .......... .......... .......... 98%  623K 0s\n",
            " 10700K .......... .......... .......... .......... .......... 98%  127M 0s\n",
            " 10750K .......... .......... .......... .......... .......... 99%  621K 0s\n",
            " 10800K .......... .......... .......... .......... .......... 99%  624K 0s\n",
            " 10850K .......... .......                                    100% 99.3M=14s\n",
            "\n",
            "2022-02-02 21:04:38 (781 KB/s) - ‘Roms.rar.1’ saved [11128004/11128004]\n",
            "\n",
            "\n",
            "\n",
            "Would you like to replace the existing file HC ROMS.zip\n",
            "11826711 bytes, modified on 2019-12-22 11:24\n",
            "with a new one\n",
            "11826711 bytes, modified on 2019-12-22 11:24\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit \n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit \n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "import random\n",
        "import time\n",
        "from typing import Any, List, Sequence, Tuple\n",
        "from os.path import exists\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras.models import Sequential, clone_model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "\n",
        "from colabgymrender.recorder import Recorder"
      ],
      "metadata": {
        "id": "JH9AxXJuc1j_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Memory():\n",
        "    def __init__(self,max_len):\n",
        "        self.max_len = max_len\n",
        "        self.frames = deque(maxlen = max_len)\n",
        "        self.actions = deque(maxlen = max_len)\n",
        "        self.rewards = deque(maxlen = max_len)\n",
        "        self.done_flags = deque(maxlen = max_len)\n",
        "\n",
        "    def add_experience(self,next_frame, next_frames_reward, next_action, next_frame_terminal):\n",
        "        self.frames.append(next_frame)\n",
        "        self.actions.append(next_action)\n",
        "        self.rewards.append(next_frames_reward)\n",
        "        self.done_flags.append(next_frame_terminal)"
      ],
      "metadata": {
        "id": "WPtDtkmAdh1u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "    def __init__(self,possible_actions,starting_mem_len,max_mem_len,starting_epsilon,learn_rate, starting_lives = 5, debug = False):\n",
        "        self.memory = Memory(max_mem_len)\n",
        "        self.possible_actions = possible_actions\n",
        "        self.epsilon = starting_epsilon\n",
        "        self.epsilon_decay = .9/100000\n",
        "        self.epsilon_min = .05\n",
        "        self.gamma = .95\n",
        "        self.learn_rate = learn_rate\n",
        "        self.model = self._build_model()\n",
        "        self.model_target = clone_model(self.model)\n",
        "        self.total_timesteps = 0\n",
        "        self.lives = starting_lives #this parameter does not apply to pong\n",
        "        self.starting_mem_len = starting_mem_len\n",
        "        self.learns = 0\n",
        "\n",
        "\n",
        "    def _build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Input((84,84,4)))\n",
        "        model.add(Conv2D(filters = 32,kernel_size = (8,8),strides = 4,data_format=\"channels_last\", activation = 'relu',kernel_initializer = tf.keras.initializers.VarianceScaling(scale=2)))\n",
        "        model.add(Conv2D(filters = 64,kernel_size = (4,4),strides = 2,data_format=\"channels_last\", activation = 'relu',kernel_initializer = tf.keras.initializers.VarianceScaling(scale=2)))\n",
        "        model.add(Conv2D(filters = 64,kernel_size = (3,3),strides = 1,data_format=\"channels_last\", activation = 'relu',kernel_initializer = tf.keras.initializers.VarianceScaling(scale=2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512,activation = 'relu', kernel_initializer = tf.keras.initializers.VarianceScaling(scale=2)))\n",
        "        model.add(Dense(len(self.possible_actions), activation = 'linear'))\n",
        "        optimizer = Adam(self.learn_rate)\n",
        "        model.compile(optimizer, loss=tf.keras.losses.Huber())\n",
        "        model.summary()\n",
        "        print('\\nAgent Initialized\\n')\n",
        "        return model\n",
        "\n",
        "    def get_action(self,state):\n",
        "        \"\"\"Explore\"\"\"\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return random.sample(self.possible_actions,1)[0]\n",
        "\n",
        "        \"\"\"Do Best Acton\"\"\"\n",
        "        a_index = np.argmax(self.model.predict(state))\n",
        "        return self.possible_actions[a_index]\n",
        "\n",
        "    def _index_valid(self,index):\n",
        "        if self.memory.done_flags[index-3] or self.memory.done_flags[index-2] or self.memory.done_flags[index-1] or self.memory.done_flags[index]:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "    def save_checkpoint(self, path):\n",
        "        self.model.save_weights(path + 'recent_weights.hdf5')\n",
        "        with open(path + \"epsilon.txt\", \"w\") as f:\n",
        "            f.write(str(self.epsilon))\n",
        "        print('saved checkpoint to {}'.format(path))\n",
        "        \n",
        "    def load_checkpoint(self, path):\n",
        "        self.model.load_weights(path + 'recent_weights.hdf5')\n",
        "        epsilon_path = path + \"epsilon.txt\"\n",
        "        with open(epsilon_path, \"r\") as f:\n",
        "            self.epsilon = float(f.read())\n",
        "            print(\"loaded epsilon = {} from {}\".format(self.epsilon, epsilon_path))\n",
        "\n",
        "    def learn(self,debug = False):\n",
        "        \"\"\"we want the output[a] to be R_(t+1) + Qmax_(t+1).\"\"\"\n",
        "        \"\"\"So target for taking action 1 should be [output[0], R_(t+1) + Qmax_(t+1), output[2]]\"\"\"\n",
        "\n",
        "        \"\"\"First we need 32 random valid indicies\"\"\"\n",
        "        states = []\n",
        "        next_states = []\n",
        "        actions_taken = []\n",
        "        next_rewards = []\n",
        "        next_done_flags = []\n",
        "\n",
        "        while len(states) < 32:\n",
        "            index = np.random.randint(4,len(self.memory.frames) - 1)\n",
        "            if self._index_valid(index):\n",
        "                state = [self.memory.frames[index-3], self.memory.frames[index-2], self.memory.frames[index-1], self.memory.frames[index]]\n",
        "                state = np.moveaxis(state,0,2)/255\n",
        "                next_state = [self.memory.frames[index-2], self.memory.frames[index-1], self.memory.frames[index], self.memory.frames[index+1]]\n",
        "                next_state = np.moveaxis(next_state,0,2)/255\n",
        "\n",
        "                states.append(state)\n",
        "                next_states.append(next_state)\n",
        "                actions_taken.append(self.memory.actions[index])\n",
        "                next_rewards.append(self.memory.rewards[index+1])\n",
        "                next_done_flags.append(self.memory.done_flags[index+1])\n",
        "\n",
        "        \"\"\"Now we get the ouputs from our model, and the target model. We need this for our target in the error function\"\"\"\n",
        "        labels = self.model.predict(np.array(states))\n",
        "        next_state_values = self.model_target.predict(np.array(next_states))\n",
        "        \n",
        "        \"\"\"Now we define our labels, or what the output should have been\n",
        "           We want the output[action_taken] to be R_(t+1) + Qmax_(t+1) \"\"\"\n",
        "        for i in range(32):\n",
        "            action = self.possible_actions.index(actions_taken[i])\n",
        "            labels[i][action] = next_rewards[i] + (not next_done_flags[i]) * self.gamma * max(next_state_values[i])\n",
        "\n",
        "        \"\"\"Train our model using the states and outputs generated\"\"\"\n",
        "        self.model.fit(np.array(states),labels,batch_size = 32, epochs = 1, verbose = 0)\n",
        "\n",
        "        \"\"\"Decrease epsilon and update how many times our agent has learned\"\"\"\n",
        "        # tf.print(\"epsilon {} epsilon_min {} epsilon_decay{}\".format(self.epsilon, self.epsilon_min, self.epsilon_decay))\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon -= self.epsilon_decay\n",
        "            \n",
        "        self.learns += 1\n",
        "        \n",
        "        \"\"\"Every 10000 learned, copy our model weights to our target model\"\"\"\n",
        "        if self.learns % 10000 == 0:\n",
        "            self.model_target.set_weights(self.model.get_weights())\n",
        "            print('\\nTarget model updated')"
      ],
      "metadata": {
        "id": "RUsLdyCld37G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_frame(frame):\n",
        "    frame = frame[30:-12,5:-4]\n",
        "    frame = np.average(frame,axis = 2)\n",
        "    frame = cv2.resize(frame,(84,84),interpolation = cv2.INTER_NEAREST)\n",
        "    frame = np.array(frame,dtype = np.uint8)\n",
        "    return frame\n",
        "\n",
        "def initialize_new_game(name, env, agent):\n",
        "    \"\"\"We don't want an agents past game influencing its new game, so we add in some dummy data to initialize\"\"\"\n",
        "    \n",
        "    env.reset()\n",
        "    starting_frame = resize_frame(env.step(0)[0])\n",
        "\n",
        "    dummy_action = 0\n",
        "    dummy_reward = 0\n",
        "    dummy_done = False\n",
        "    for i in range(3):\n",
        "        agent.memory.add_experience(starting_frame, dummy_reward, dummy_action, dummy_done)\n",
        "\n",
        "def make_env(name, agent):\n",
        "    env = gym.make(name)\n",
        "    env = Recorder(env, 'recordings')\n",
        "    return env\n",
        "    \n",
        "# Wrap OpenAI Gym's `env.step` call as an operation in a TensorFlow function.\n",
        "# This would allow it to be included in a callable TensorFlow graph.\n",
        "# @tf.function\n",
        "def env_step(action: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "  \"\"\"Returns state, reward and done flag given an action.\"\"\"\n",
        "\n",
        "  state, reward, done, _ = env.step(action)\n",
        "  return (state.astype(np.float32), \n",
        "          np.array(reward, np.int32), \n",
        "          np.array(done, np.int32))\n",
        "\n",
        "\n",
        "# def tf_env_step(action: tf.Tensor) -> List[tf.Tensor]:\n",
        "#   return tf.numpy_function(env_step, [action], \n",
        "#                            [tf.float32, tf.int32, tf.int32])\n",
        "# @tf.function\n",
        "def take_step(name, env, agent, score, debug):\n",
        "    \n",
        "    #1 and 2: Update timesteps and save weights\n",
        "    agent.total_timesteps += 1\n",
        "    # if agent.total_timesteps % 50000 == 0:\n",
        "    #     agent.save_checkpoint()\n",
        "    #   agent.model.save_weights('recent_weights.hdf5')\n",
        "    #   print('\\nWeights saved!')\n",
        "\n",
        "    #3: Take action\n",
        "    next_frame, next_frames_reward, next_frame_terminal = env_step(agent.memory.actions[-1])\n",
        "    \n",
        "    #4: Get next state\n",
        "    next_frame = resize_frame(next_frame)\n",
        "    new_state = [agent.memory.frames[-3], agent.memory.frames[-2], agent.memory.frames[-1], next_frame]\n",
        "    new_state = np.moveaxis(new_state,0,2)/255 #We have to do this to get it into keras's goofy format of [batch_size,rows,columns,channels]\n",
        "    new_state = np.expand_dims(new_state,0) #^^^\n",
        "    \n",
        "    #5: Get next action, using next state\n",
        "    next_action = agent.get_action(new_state)\n",
        "\n",
        "    #6: If game is over, return the score\n",
        "    if next_frame_terminal:\n",
        "        agent.memory.add_experience(next_frame, next_frames_reward, next_action, next_frame_terminal)\n",
        "        return (score + next_frames_reward),True\n",
        "\n",
        "    #7: Now we add the next experience to memory\n",
        "    agent.memory.add_experience(next_frame, next_frames_reward, next_action, next_frame_terminal)\n",
        "\n",
        "    #8: If we are trying to debug this then render\n",
        "    if debug:\n",
        "        env.render()\n",
        "\n",
        "    #9: If the threshold memory is satisfied, make the agent learn from memory\n",
        "    # tf.print(\"len(agent.memory.frames) {} agent.starting_mem_len {}\".format(len(agent.memory.frames), agent.starting_mem_len))\n",
        "    if len(agent.memory.frames) > agent.starting_mem_len:\n",
        "        agent.learn(debug)\n",
        "\n",
        "    return (score + next_frames_reward),False\n",
        "\n",
        "\n",
        "# @tf.function\n",
        "def play_episode(name, env, agent, debug = False):\n",
        "    initialize_new_game(name, env, agent)\n",
        "    \n",
        "    done = False\n",
        "    score = 0\n",
        "    while True:\n",
        "        score,done = take_step(name,env,agent,score, debug)\n",
        "        if done:\n",
        "            break\n",
        "    \n",
        "    return score\n"
      ],
      "metadata": {
        "id": "TJngELbRdtxO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'Pong-v0'\n",
        "\n",
        "agent = Agent(possible_actions=[0,2,3],starting_mem_len=5000,max_mem_len=50000,starting_epsilon = 1, learn_rate = .00025)\n",
        "env = make_env(name,agent)\n",
        "\n",
        "last_100_avg = [-21]\n",
        "scores = deque(maxlen = 100)\n",
        "max_score = -21\n",
        "\n",
        "checkpoint_path = '/content/gdrive/My Drive/Colab Notebooks/pong/'\n",
        "saved_weights_path = '/content/gdrive/My Drive/Colab Notebooks/pong/recent_weights.hdf5'\n",
        "epsilon_path = '/content/gdrive/My Drive/Colab Notebooks/pong/epsilon.txt'\n",
        "\n",
        "if exists(saved_weights_path) and exists(epsilon_path):\n",
        "    agent.load_checkpoint(checkpoint_path)\n",
        "    # agent.epsilon = 0\n",
        "\n",
        "env.reset()\n",
        "\n",
        "for i in range(100):\n",
        "    timesteps = agent.total_timesteps\n",
        "    timee = time.time()\n",
        "    score = play_episode(name, env, agent, debug = False) #set debug to true for rendering\n",
        "    scores.append(score)\n",
        "    if score > max_score:\n",
        "        max_score = score\n",
        "\n",
        "    print('\\nEpisode: ' + str(i))\n",
        "    print('Steps: ' + str(agent.total_timesteps - timesteps))\n",
        "    print('Duration: ' + str(time.time() - timee))\n",
        "    print('Score: ' + str(score))\n",
        "    print('Max Score: ' + str(max_score))\n",
        "    print('Epsilon: ' + str(agent.epsilon))\n",
        "    print('Memory frames: ' + str(len(agent.memory.frames)))\n",
        "\n",
        "    if i%10 == 0:\n",
        "      env.play()\n",
        "      agent.save_checkpoint(checkpoint_path)\n",
        "\n",
        "    if i%100==0 and i!=0:\n",
        "        last_100_avg.append(sum(scores)/len(scores))\n",
        "        plt.plot(np.arange(0,i+1,100),last_100_avg)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "XmaDSWhLNS59",
        "outputId": "0bd78e99-45c1-41fd-f0a1-817e088c2704"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ffa59543ef4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Pong-v0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstarting_mem_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_mem_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstarting_epsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.00025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Agent' is not defined"
          ]
        }
      ]
    }
  ]
}